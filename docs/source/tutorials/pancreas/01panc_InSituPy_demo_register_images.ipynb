{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16df72d-5dd5-47da-a8c3-b569fe97446b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# InSituPy demonstration - Register images\n",
    "\n",
    "This notebook demonstrates the registration of images from H&E, IHC or IF stainings that were performed on the same slide as the Xenium In Situ measurements. It is assumed that the images which are about to be registered, contain the same tissue as the spatial transcriptomics data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc0c4ed-3587-460e-98d2-6626a020a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following code ensures that all functions and init files are reloaded before executions.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd4391",
   "metadata": {},
   "source": [
    "## Load Xenium data into `InSituData` object\n",
    "\n",
    "Now the Xenium data can be parsed by providing the data path to `InSituData` using the `read_xenium` function or directly using the downloading function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1f8cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from insitupy import read_xenium, register_images, CACHE\n",
    "from insitupy.datasets import human_pancreatic_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245e63c1",
   "metadata": {},
   "source": [
    "### Load the dataset directly from the downloading function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a2d536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset exists already. Download is skipped. To force download set `overwrite=True`.\n",
      "Image exists. Checking md5sum...\n",
      "The md5sum matches. Download is skipped. To force download set `overwrite=True`.\n",
      "Image exists. Checking md5sum...\n",
      "The md5sum matches. Download is skipped. To force download set `overwrite=True`.\n",
      "Corresponding image data can be found in C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\unregistered_images\n",
      "For this dataset following images are available:\n",
      "slide_id__hPancreas__HE__histo.ome.tiff\n",
      "slide_id__hPancreas__CD20_TROP2_PPY_DAPI__IFIF_image_name.ome.tiff\n",
      "Loading cells...\n",
      "Loading images...\n",
      "Loading transcripts...\n"
     ]
    }
   ],
   "source": [
    "xd = human_pancreatic_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff42adc5",
   "metadata": {},
   "source": [
    "### ... or use the `read_xenium` function and the path to the Xenium data directory if the dataset has already been downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7f0cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cells...\n",
      "Loading images...\n",
      "Loading transcripts...\n"
     ]
    }
   ],
   "source": [
    "xd = read_xenium(CACHE / \"demo_datasets/hpancreas/output-XETG00000__slide_id__hpancreas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201d17cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[31mInSituData\u001b[0m\n",
       "\u001b[1mMethod:\u001b[0m\t\tXenium\n",
       "\u001b[1mSlide ID:\u001b[0m\t0009465\n",
       "\u001b[1mSample ID:\u001b[0m\thPancreas_cancer\n",
       "\u001b[1mPath:\u001b[0m\t\tC:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\output-XETG00000__slide_id__hpancreas\n",
       "\u001b[1mMetadata file:\u001b[0m\texperiment.xenium\n",
       "    ➤ \u001b[34m\u001b[1mimages\u001b[0m\n",
       "       \u001b[1mnuclei:\u001b[0m\t(13752, 48274)\n",
       "    ➤\u001b[32m\u001b[1m cells\u001b[0m\n",
       "       \u001b[1mmatrix\u001b[0m\n",
       "           AnnData object with n_obs × n_vars = 190965 × 474\n",
       "           obs: 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area'\n",
       "           var: 'gene_ids', 'feature_types', 'genome'\n",
       "           obsm: 'spatial'\n",
       "       \u001b[1mboundaries\u001b[0m\n",
       "           BoundariesData object with 2 entries:\n",
       "               \u001b[1mcells\u001b[0m\n",
       "               \u001b[1mnuclei\u001b[0m\n",
       "    ➤\u001b[95m\u001b[1m transcripts\u001b[0m\n",
       "       DataFrame with shape 28455659 x 9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bee01b",
   "metadata": {},
   "source": [
    "### Prepare the paths to the unregistered images\n",
    "\n",
    "Here the unregistered images were downloaded by the `human_pancreas_cancer` downloading function and saved in a folder `unregistered_images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd89fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare paths\n",
    "if_to_be_registered = CACHE / \"demo_datasets/hpancreas\" / \"unregistered_images/slide_id__hPancreas__CD20_TROP2_PPY_DAPI__IF.ome.tif\"\n",
    "he_to_be_registered = CACHE / \"demo_datasets/hpancreas\" / \"unregistered_images/slide_id__hPancreas__HE__histo.ome.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd74b4",
   "metadata": {},
   "source": [
    "### Automated Registration of Images\n",
    "\n",
    "**Overview:**\n",
    "_Xenium In Situ_ is a non-destructive method that allows for staining and imaging of tissue after in situ sequencing analysis. This process is performed outside the _Xenium_ machine and requires subsequent registration. `InSituPy` provides an automatic image registration pipeline based on the [Scale-Invariant Feature Transform (SIFT) algorithm](https://link.springer.com/article/10.1023/B:VISI.0000029664.99615.94).\n",
    "\n",
    "**Process:**\n",
    "1. **Feature Detection:**\n",
    "   - The SIFT algorithm detects common features between the template (_Xenium_ DAPI image) and the acquired images.\n",
    "   - These features are used to calculate a transformation matrix.\n",
    "   - The transformation matrix registers the images to the template.\n",
    "\n",
    "<left><img src=\"../demo_screenshots/common_features.png\" width=\"800\"/></left>\n",
    "\n",
    "*Common features extracted by SIFT algorithm*\n",
    "\n",
    "2. **Preprocessing Steps:**\n",
    "   - **Histological Images (H&E or IHC):**\n",
    "     - These techniques produce RGB images.\n",
    "     - Color deconvolution extracts the hematoxylin channel containing the nuclei for registration with the _Xenium_ DAPI image.\n",
    "   - **Immunofluorescence (IF) Images:**\n",
    "     - This method results in multiple grayscale images.\n",
    "     - One channel must contain a nuclei stain (e.g., DAPI).\n",
    "     - This channel is selected for SIFT feature detection and transformation matrix calculation.\n",
    "     - Other channels are registered using the same transformation matrix.\n",
    "\n",
    "### Cropping of Images from Whole Slide Images\n",
    "\n",
    "**Workflow:**\n",
    "In a Xenium In Situ workflow, a slide often contains multiple tissue sections. While spatial transcriptomics data is separated during the run, histological stainings contain all sections in one whole slide image. To extract individual images of histologically stained tissue sections, two workflows are recommended:\n",
    "\n",
    "1. **QuPath Annotation:**\n",
    "   - Annotate and name individual tissue sections in QuPath.\n",
    "   - Use the `.groovy` script in `InSituPy/scripts/export_annotations_OME-TIFF.groovy`.\n",
    "\n",
    "2. **Napari-Based Approach:**\n",
    "   - Demonstrated in `XX_InSituPy_extract_individual_images.ipynb`.\n",
    "\n",
    "### Input Files\n",
    "\n",
    "**Formats:**\n",
    "- **.tif** or **.ome.tif** formats are accepted.\n",
    "- **IF Images:**\n",
    "  - Multi-channel images are expected.\n",
    "  - Specify channel names using the `channel_names` argument.\n",
    "  - Specify the channel containing nuclei staining with the `channel_name_for_registration` argument (e.g., DAPI channel).\n",
    "- **HE Images:**\n",
    "  - Expected to be RGB images.\n",
    "  - Cropping methods should result in the correct image format.\n",
    "\n",
    "### Output Generated by the Registration Pipeline\n",
    "\n",
    "1. **Registered Images:**\n",
    "   - If `save_registered_images==True`, registered images are saved as `.ome.tif` in the `registered_images` folder in the parent directory of the _Xenium_ data.\n",
    "   - File naming convention: `slide_id__sample_id__name__registered.ome.tif`.\n",
    "\n",
    "2. **Transformation Matrix:**\n",
    "   - Saved as `.csv` in the `registration_qc` folder within the `registered_images` folder.\n",
    "   - File name ends with `__T.pdf`.\n",
    "\n",
    "3. **Common Features:**\n",
    "   - Representation of common features between the registered image and the template.\n",
    "   - Saved as `.pdf` in the `registration_qc` folder.\n",
    "   - File name ends with `__common_features`.\n",
    "\n",
    "**Directory Structure:**\n",
    "```\n",
    "./demo_dataset\n",
    "├───output-XETG00000__slide_id__sample_id\n",
    "├───registered_images\n",
    "│   │   slide_id__sample_id__name__registered.ome.tif\n",
    "│   ├───registration_qc\n",
    "│   │       slide_id__sample_id__name__T.csv\n",
    "│   │       slide_id__sample_id__name__common_features.pdf\n",
    "└───unregistered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f63509",
   "metadata": {},
   "source": [
    "## Registration of IF images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d24fd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessing following IF images: \u001b[1mCD20, TROP2, PPY, DAPI\u001b[0m\n",
      "\t\tLoading images to be registered...\n",
      "\t\tSelect image with nuclei from IF image (channel index: 3)\n",
      "Load and scale image data containing all channels.\n",
      "\t\tLoad image into memory...\n",
      "\t\tLoad template into memory...\n",
      "\t\tRescale image and template to save memory.\n",
      "\t\t\tRescaled from (4, 17091, 58644) to following dimensions: (4, 2159, 7409)\n",
      "\t\t\tRescaled from (13752, 48274) to following dimensions: (2134, 7494)\n",
      "\t\tConvert scaled images to 8 bit\n",
      "\t\tWarning: Dimensions of image ((4, 17091, 58644)) exceed C++ limit SHRT_MAX (32767). Image dimensions are resized to meet requirements. This leads to a loss of quality.\n",
      "Image dimensions after resizing: (4, 9549, 32766). Resize factor: 0.5587272355228157\n",
      "Load and scale image data containing only the channels required for registration.\n",
      "\t\tRescale image and template to save memory.\n",
      "\t\t\tRescaled from (17091, 58644) to following dimensions: (2159, 7409)\n",
      "\t\t\tRescaled from (13752, 48274) to following dimensions: (2134, 7494)\n",
      "\t\tConvert scaled images to 8 bit\n",
      "\t\tWarning: Dimensions of image ((17091, 58644)) exceed C++ limit SHRT_MAX (32767). Image dimensions are resized to meet requirements. This leads to a loss of quality.\n",
      "Image dimensions after resizing: (9549, 32766). Resize factor: 0.5587272355228157\n",
      "\t\tExtract common features from image and template\n",
      "\t\t2025-02-15 21:48:38: Get features...\n",
      "\t\t\tAdjust contrast with clip method...\n",
      "\t\t\tMethod: SIFT...\n",
      "\t\t2025-02-15 21:48:46: Compute matches...\n",
      "\t\t2025-02-15 21:49:12: Filter matches...\n",
      "\t\t\tSufficient number of good matches found (56815/149).\n",
      "\t\t2025-02-15 21:49:12: Display matches...\n",
      "\t\t2025-02-15 21:49:27: Fetch keypoints...\n",
      "\t\t2025-02-15 21:49:27: Estimate 2D affine transformation matrix...\n",
      "\t\tEstimate affine transformation matrix for resized image\n",
      "\t\t2025-02-15 21:49:30: Register image by affine transformation...\n",
      "\t\tSave OME-TIFF to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\0009465__hPancreas_cancer__CD20__registered.ome.tif\n",
      "\t\tSave QC files to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\registration_qc\n",
      "\t\t2025-02-15 21:49:44: Register image by affine transformation...\n",
      "\t\tSave OME-TIFF to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\0009465__hPancreas_cancer__TROP2__registered.ome.tif\n",
      "\t\tSave QC files to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\registration_qc\n",
      "\t\t2025-02-15 21:50:01: Register image by affine transformation...\n",
      "\t\tSave OME-TIFF to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\0009465__hPancreas_cancer__PPY__registered.ome.tif\n",
      "\t\tSave QC files to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\registration_qc\n"
     ]
    }
   ],
   "source": [
    "register_images(\n",
    "    data=xd,\n",
    "    image_to_be_registered=if_to_be_registered,\n",
    "    image_type=\"IF\",\n",
    "    channel_names=['CD20', 'TROP2', 'PPY', 'DAPI'],\n",
    "    channel_name_for_registration=\"DAPI\",\n",
    "    template_image_name=\"nuclei\",\n",
    "    save_registered_images=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fbab9e",
   "metadata": {},
   "source": [
    "## Registration of H&E images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed1c248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tProcessing following histo images: \u001b[1mHE\u001b[0m\n",
      "\t\tLoading images to be registered...\n",
      "\t\tRun color deconvolution\n",
      "Load and scale image data containing all channels.\n",
      "\t\tLoad image into memory...\n",
      "\t\tLoad template into memory...\n",
      "\t\tRescale image and template to save memory.\n",
      "\t\t\tRescaled from (71883, 20562, 3) to following dimensions: (7478, 2139, 3)\n",
      "\t\t\tRescaled from (13752, 48274) to following dimensions: (2134, 7494)\n",
      "\t\tConvert scaled images to 8 bit\n",
      "\t\tWarning: Dimensions of image ((71883, 20562, 3)) exceed C++ limit SHRT_MAX (32767). Image dimensions are resized to meet requirements. This leads to a loss of quality.\n",
      "Image dimensions after resizing: (32766, 9372, 3). Resize factor: 0.4558240474103752\n",
      "Load and scale image data containing only the channels required for registration.\n",
      "\t\tRescale image and template to save memory.\n",
      "\t\t\tRescaled from (71880, 20560) to following dimensions: (7479, 2139)\n",
      "\t\t\tRescaled from (13752, 48274) to following dimensions: (2134, 7494)\n",
      "\t\tConvert scaled images to 8 bit\n",
      "\t\tWarning: Dimensions of image ((71880, 20560)) exceed C++ limit SHRT_MAX (32767). Image dimensions are resized to meet requirements. This leads to a loss of quality.\n",
      "Image dimensions after resizing: (32766, 9372). Resize factor: 0.4558430717863105\n",
      "\t\tExtract common features from image and template\n",
      "\t\t2025-02-15 21:50:47: Get features...\n",
      "\t\t\tAdjust contrast with clip method...\n",
      "\t\t\tMethod: SIFT...\n",
      "\t\t2025-02-15 21:50:57: Compute matches...\n",
      "\t\t2025-02-15 21:51:21: Filter matches...\n",
      "\t\t\tSufficient number of good matches found (12943/149).\n",
      "\t\t2025-02-15 21:51:21: Display matches...\n",
      "\t\t2025-02-15 21:51:26: Fetch keypoints...\n",
      "\t\t2025-02-15 21:51:27: Estimate 2D affine transformation matrix...\n",
      "\t\tEstimate affine transformation matrix for resized image\n",
      "\t\t2025-02-15 21:51:27: Register image by affine transformation...\n",
      "\t\tSave OME-TIFF to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\__0009465__hPancreas_cancer__HE__registered.ome.tif\n",
      "\t\tSave QC files to C:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\registered_images\\registration_qc\n"
     ]
    }
   ],
   "source": [
    "register_images(\n",
    "    data=xd,\n",
    "    image_to_be_registered=he_to_be_registered,\n",
    "    image_type=\"histo\",\n",
    "    channel_names='HE',\n",
    "    template_image_name=\"nuclei\",\n",
    "    save_registered_images=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c765c431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[31mInSituData\u001b[0m\n",
       "\u001b[1mMethod:\u001b[0m\t\tXenium\n",
       "\u001b[1mSlide ID:\u001b[0m\t0009465\n",
       "\u001b[1mSample ID:\u001b[0m\thPancreas_cancer\n",
       "\u001b[1mPath:\u001b[0m\t\tC:\\Users\\ge37voy\\.cache\\InSituPy\\demo_datasets\\hpancreas\\output-XETG00000__slide_id__hpancreas\n",
       "\u001b[1mMetadata file:\u001b[0m\texperiment.xenium\n",
       "    ➤ \u001b[34m\u001b[1mimages\u001b[0m\n",
       "       \u001b[1mnuclei:\u001b[0m\t(13752, 48274)\n",
       "       \u001b[1mCD20:\u001b[0m\t(13752, 48274)\n",
       "       \u001b[1mTROP2:\u001b[0m\t(13752, 48274)\n",
       "       \u001b[1mPPY:\u001b[0m\t(13752, 48274)\n",
       "       \u001b[1mHE:\u001b[0m\t(13752, 48274, 3)\n",
       "    ➤\u001b[32m\u001b[1m cells\u001b[0m\n",
       "       \u001b[1mmatrix\u001b[0m\n",
       "           AnnData object with n_obs × n_vars = 190965 × 474\n",
       "           obs: 'transcript_counts', 'control_probe_counts', 'control_codeword_counts', 'unassigned_codeword_counts', 'deprecated_codeword_counts', 'total_counts', 'cell_area', 'nucleus_area'\n",
       "           var: 'gene_ids', 'feature_types', 'genome'\n",
       "           obsm: 'spatial'\n",
       "       \u001b[1mboundaries\u001b[0m\n",
       "           BoundariesData object with 2 entries:\n",
       "               \u001b[1mcells\u001b[0m\n",
       "               \u001b[1mnuclei\u001b[0m\n",
       "    ➤\u001b[95m\u001b[1m transcripts\u001b[0m\n",
       "       DataFrame with shape 28455659 x 9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b91b3af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8290321",
   "metadata": {},
   "source": [
    "## Working with an `InSituPy` project\n",
    "\n",
    "To allow a simple and structured saving workflow, `InSituPy` provides two saving functions:\n",
    "- `saveas()`\n",
    "- `save()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50fad9",
   "metadata": {},
   "source": [
    "\n",
    "### Save as `InSituPy` project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9e13a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "insitupy_project = Path(CACHE / \"out/demo_panc_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fc7001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to C:\\Users\\ge37voy\\.cache\\InSituPy\\out\\demo_panc_project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ge37voy\\Github\\InSituPy\\insitupy\\images\\utils.py:211: UserWarning: Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\n",
      "  warnings.warn(\"Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\")\n",
      "C:\\Users\\ge37voy\\Github\\InSituPy\\insitupy\\images\\utils.py:211: UserWarning: Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\n",
      "  warnings.warn(\"Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ge37voy\\Github\\InSituPy\\insitupy\\_warnings.py:5: UserWarning: Loading functions only work on a saved InSituPy project.\n",
      "  warn(\"Loading functions only work on a saved InSituPy project.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xd.saveas(insitupy_project, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8a3cba",
   "metadata": {},
   "source": [
    "### Save `InSituPy` project with downscaled image data\n",
    "\n",
    "Since the image data is very large and not required during most of the trancriptomic analysis, we can downscale the image data to save disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c2dc284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to C:\\Users\\ge37voy\\.cache\\InSituPy\\out\\demo_panc_project_downscaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ge37voy\\Github\\InSituPy\\insitupy\\images\\utils.py:211: UserWarning: Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\n",
      "  warnings.warn(\"Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\")\n",
      "C:\\Users\\ge37voy\\Github\\InSituPy\\insitupy\\images\\utils.py:211: UserWarning: Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\n",
      "  warnings.warn(\"Image does not have dtype 'uint8' or 'uint16'. Is converted to 'uint16'.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ge37voy\\Github\\InSituPy\\insitupy\\_warnings.py:5: UserWarning: Loading functions only work on a saved InSituPy project.\n",
      "  warn(\"Loading functions only work on a saved InSituPy project.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "insitupy_project_downscaled = Path(CACHE / \"out/demo_panc_project_downscaled\")\n",
    "xd.saveas(\n",
    "    insitupy_project_downscaled, overwrite=True,\n",
    "    images_max_resolution=1 # in µm/pixel\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726fab84",
   "metadata": {},
   "source": [
    "### Reload from `InSituPy` project\n",
    "\n",
    "From the `InSituPy` project we can now load only the modalities that we need for later analyses. Due to an optimized file structure using `zarr` and `dask`, this makes loading and visualization of the data more efficient compared to doing this directly from the xenium data bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05ff70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from insitupy import InSituData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cfa5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd = InSituData.read(insitupy_project)\n",
    "xd_ds = InSituData.read(insitupy_project_downscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f5f2cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[31mInSituData\u001b[0m\n",
       "\u001b[1mMethod:\u001b[0m\t\tXenium\n",
       "\u001b[1mSlide ID:\u001b[0m\t0009465\n",
       "\u001b[1mSample ID:\u001b[0m\thPancreas_cancer\n",
       "\u001b[1mPath:\u001b[0m\t\tC:\\Users\\ge37voy\\.cache\\InSituPy\\out\\demo_panc_project\n",
       "\u001b[1mMetadata file:\u001b[0m\t.ispy\n",
       "\n",
       "No modalities loaded."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b912516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1m\u001b[31mInSituData\u001b[0m\n",
       "\u001b[1mMethod:\u001b[0m\t\tXenium\n",
       "\u001b[1mSlide ID:\u001b[0m\t0009465\n",
       "\u001b[1mSample ID:\u001b[0m\thPancreas_cancer\n",
       "\u001b[1mPath:\u001b[0m\t\tC:\\Users\\ge37voy\\.cache\\InSituPy\\out\\demo_panc_project_downscaled\n",
       "\u001b[1mMetadata file:\u001b[0m\t.ispy\n",
       "\n",
       "No modalities loaded."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b68706",
   "metadata": {},
   "source": [
    "### Load all required modalities\n",
    "\n",
    "Next, we have to make sure that all data modalities that are required for the subsequent analyses are loaded. In our case it is the cellular data and the image data. If a modality is missing, one can load it with `.load_{modality}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2082723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_ds.load_cells()\n",
    "xd_ds.load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8dfa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xd_ds.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aa8c32",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testtest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
